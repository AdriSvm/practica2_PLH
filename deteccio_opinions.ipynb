{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "import pandas as pd\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Creem un diccionari de documents on posarem el text de cada document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_pos_docs = {}\n",
    "te_pos_docs = {}\n",
    "for i,val in enumerate(mr.fileids('pos')):\n",
    "    if i < len(mr.fileids('pos'))*0.9:\n",
    "        tr_pos_docs[val] = mr.raw(val)\n",
    "    else:\n",
    "        te_pos_docs[val] = mr.raw(val)\n",
    "\n",
    "tr_neg_docs = {}\n",
    "te_neg_docs = {}\n",
    "for i,val in enumerate(mr.fileids('neg')):\n",
    "    if i < len(mr.fileids('neg'))*0.9:\n",
    "        tr_neg_docs[val] = mr.raw(val)\n",
    "    else:\n",
    "        te_neg_docs[val] = mr.raw(val)\n",
    "\n",
    "tr_neg_docs.update(tr_pos_docs)\n",
    "te_neg_docs.update(te_pos_docs)\n",
    "train = tr_neg_docs \n",
    "test = te_neg_docs\n",
    "\n",
    "\n",
    "\n",
    "#1800 documents per train i 200 per test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "#### Fem la primer neteja de carácters que no aporten informació així com preprocés bàsic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo re elimina todos los signos de puntuación !! (así se quita los accentos raros que salian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    train[i] = train[i].replace(\"&nbsp ;\",\"\")\n",
    "    train[i] = train[i].replace(\"\\n\", \"\")\n",
    "    train[i] = train[i].lower()\n",
    "    train[i] = re.sub(r\"\\d\",\"\",train[i])\n",
    "    train[i] = re.sub(r'[^\\w\\s]', '', train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenitzador = lambda x: nltk.word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1800x159 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93766 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CountVectorizer(strip_accents='ascii',lowercase=True,tokenizer=tokenitzador,stop_words=stop_words, min_df=0.2)\n",
    "X.fit_transform(train.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = X.get_feature_names()\n",
    "df = pd.DataFrame(columns=[\"sentimiento\"] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(train.keys()):\n",
    "    valor = X.transform([train[val]]).toarray()\n",
    "    df.loc[len(df)] = [val[0:3]] + list(valor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.get_feature_names()\n",
    "df_test = pd.DataFrame(columns=[\"sentimiento\"] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(test.keys()):\n",
    "    valor = X.transform([test[val]]).toarray()\n",
    "    df_test.loc[len(df_test)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creem el model inicial, farem servir random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train: 1.0 \n",
      " Accuracy en test: 0.77 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train.sample(frac=1, replace= True, random_state=22)\n",
    "df_test.sample(frac=1, replace= True, random_state=22)\n",
    "\n",
    "y_train = df_train[\"sentimiento\"]\n",
    "x_train = df_train.drop(columns=[\"sentimiento\"])\n",
    "\n",
    "y_test = df_test[\"sentimiento\"]\n",
    "x_test = df_test.drop(columns=[\"sentimiento\"])\n",
    "# Crear un modelo de Random Forest con 100 árboles\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=22)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Predecir la clase de los datos de prueba\n",
    "y_pred_train = rf.predict(x_train)\n",
    "y_pred_test = rf.predict(x_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, y_pred_train)} \\n Accuracy en test: {accuracy_score(y_test, y_pred_test)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature  importance\n",
      "15        bad    0.037890\n",
      "72       life    0.017656\n",
      "43       film    0.016483\n",
      "6        also    0.014815\n",
      "57      great    0.014485\n",
      "..        ...         ...\n",
      "120      seem    0.003605\n",
      "68       kind    0.003475\n",
      "63    instead    0.003387\n",
      "107  probably    0.003234\n",
      "130      sure    0.003109\n",
      "\n",
      "[159 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las importancias de las características\n",
    "df_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "\n",
    "# Ordenar el DataFrame por importancia descendente\n",
    "df_importances = df_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "print(df_importances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo\n",
    "\n",
    "Como se puede observar, el modelo toma mayor consideración a la hora de clasificar un texto cuando aparece la palabra **bad**, tambien cabe destacar que existen palabras que se fija el modelo que no tienen sentido en cuanto a significado, como preposiciones o adverbios. Es por ello, que se modificará el train para que solo se fije en nombres, adjetivos y verbos. Además, así podremos reducir la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = {}\n",
    "\n",
    "for i in train.keys():\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(train[i]))\n",
    "    frase = \"\"\n",
    "    for val in tags:\n",
    "        if val[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','NN', 'NNS', 'JJ', 'JJR', 'JJS']:\n",
    "            frase += val[0] + \" \"\n",
    "    new_train[i] = frase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vegada que hem obtingut verbs, noms y adjectius, n'hem a entrenar el nostre count vectorizer en el train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = CountVectorizer(strip_accents='ascii',lowercase=True,tokenizer=tokenitzador,stop_words=stop_words, min_df=0.2)\n",
    "X.fit_transform(new_train.values())\n",
    "\n",
    "features = X.get_feature_names()\n",
    "df_train = pd.DataFrame(columns=[\"sentimiento\"] + features)\n",
    "\n",
    "for i, val in enumerate(new_train.keys()):\n",
    "    valor = X.transform([new_train[val]]).toarray()\n",
    "    df_train.loc[len(df_train)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = X.get_feature_names()\n",
    "df_test = pd.DataFrame(columns=[\"sentimiento\"] + features)\n",
    "\n",
    "for i, val in enumerate(test.keys()):\n",
    "    valor = X.transform([test[val]]).toarray()\n",
    "    df_test.loc[len(df_test)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creem el model ambs els mateixos hiperparámetres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train: 1.0 \n",
      "Accuracy en test: 0.72 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train.sample(frac=1, replace= True, random_state=22)\n",
    "df_test.sample(frac=1, replace= True, random_state=22)\n",
    "\n",
    "y_train = df_train[\"sentimiento\"]\n",
    "x_train = df_train.drop(columns=[\"sentimiento\"])\n",
    "\n",
    "y_test = df_test[\"sentimiento\"]\n",
    "x_test = df_test.drop(columns=[\"sentimiento\"])\n",
    "# Crear un modelo de Random Forest con 100 árboles\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=22)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Predecir la clase de los datos de prueba\n",
    "y_pred_train = rf.predict(x_train)\n",
    "y_pred_test = rf.predict(x_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, y_pred_train)} \\nAccuracy en test: {accuracy_score(y_test, y_pred_test)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.74      0.67      0.71       100\n",
      "         pos       0.70      0.77      0.73       100\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.72      0.72      0.72       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x226a5cd2888>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(classification_report(y_pred= y_pred_test, y_true= y_test))\n",
    "print(\"===========================================================\")\n",
    "a = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test), display_labels=[\"neg\", \"pos\"])\n",
    "a.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirem la importància de les labels en el nou model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature  importance\n",
      "5       bad    0.044809\n",
      "26     film    0.022982\n",
      "52     life    0.022496\n",
      "64    movie    0.019646\n",
      "40    great    0.017873\n",
      "..      ...         ...\n",
      "7   becomes    0.005388\n",
      "81    right    0.005291\n",
      "41     help    0.005225\n",
      "35    given    0.005033\n",
      "48     kind    0.004845\n",
      "\n",
      "[116 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las importancias de las características\n",
    "df_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "\n",
    "# Ordenar el DataFrame por importancia descendente\n",
    "df_importances = df_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "print(df_importances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot observar, Hem reduit, en unes 60 paraules la quantitat de paraules a tenir en compte a l'hora de classificar els diferents textos. A més a més, hem aconseguit la mateixa accuracy que en l'anterior model tenint menys labels, per tant, s'ha reduit la dimensionalitat adequadament.\n",
    "\n",
    "Com es pot observar, al reduir les variables, augmenten les importàncies de les labels en el model, on la més important segueix sent **bad**.\n",
    "\n",
    "Si s'observa el report de classificcació, es pot observar com per la classe negatiu tenim més precissió que la positiva, això pot ser degut a la paraula \"bad\", que ajuda a la precisió de la negativa però pot ser existeixen exemples que no la tenen i per tant, no arribar a reconèixer bé la classe (el nivell de recall és més inferior)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
