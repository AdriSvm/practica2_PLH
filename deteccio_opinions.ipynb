{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "import pandas as pd\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Creem un diccionari de documents on posarem el text de cada document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_pos_docs = {}\n",
    "te_pos_docs = {}\n",
    "for i,val in enumerate(mr.fileids('pos')):\n",
    "    if i < len(mr.fileids('pos'))*0.9:\n",
    "        tr_pos_docs[val] = mr.words(val)\n",
    "    else:\n",
    "        te_pos_docs[val] = mr.words(val)\n",
    "\n",
    "tr_neg_docs = {}\n",
    "te_neg_docs = {}\n",
    "for i,val in enumerate(mr.fileids('neg')):\n",
    "    if i < len(mr.fileids('neg'))*0.9:\n",
    "        tr_neg_docs[val] = mr.words(val)\n",
    "    else:\n",
    "        te_neg_docs[val] = mr.words(val)\n",
    "\n",
    "tr_neg_docs.update(tr_pos_docs)\n",
    "te_neg_docs.update(te_pos_docs)\n",
    "train = tr_neg_docs \n",
    "test = te_neg_docs\n",
    "\n",
    "\n",
    "\n",
    "#1800 documents per train i 200 per test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize(p):\n",
    "  d = {'NN': 'n', 'NNS': 'n', \n",
    "       'JJ': 'a', 'JJR': 'a', 'JJS': 'a', \n",
    "       'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v', \n",
    "       'RB': 'r', 'RBR': 'r', 'RBS': 'r'}\n",
    "  if p[1] in d:\n",
    "    return wnl.lemmatize(p[0], pos=d[p[1]])\n",
    "  return p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "#### Fem la primer neteja de carácters que no aporten informació així com preprocés bàsic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo re elimina todos los signos de puntuación !! (así se quita los accentos raros que salian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train.keys():\n",
    "    train[i] = nltk.pos_tag(train[i])   \n",
    "    train[i] = [lemmatize(x) for x in train[i]]\n",
    "    train[i] = \" \".join(train[i])\n",
    "    train[i] = train[i].replace(\"&nbsp ;\",\"\")\n",
    "    train[i] = train[i].replace(\"\\n\", \"\")\n",
    "    train[i] = train[i].lower()\n",
    "    train[i] = re.sub(r\"\\d\",\"\",train[i])\n",
    "    train[i] = re.sub(r'[^\\w\\s]', '', train[i])\n",
    "\n",
    "for i in test.keys():\n",
    "    test[i] = nltk.pos_tag(test[i])   \n",
    "    test[i] = [lemmatize(x) for x in test[i]]\n",
    "    test[i] = \" \".join(test[i])\n",
    "    test[i] = test[i].replace(\"&nbsp ;\",\"\")\n",
    "    test[i] = test[i].replace(\"\\n\", \"\")\n",
    "    test[i] = test[i].lower()\n",
    "    test[i] = re.sub(r\"\\d\",\"\",test[i])\n",
    "    test[i] = re.sub(r'[^\\w\\s]', '', test[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenitzador = lambda x: nltk.word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1800x180 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 114396 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CountVectorizer(strip_accents='ascii',lowercase=True,tokenizer=tokenitzador,stop_words=stop_words, min_df=0.2)\n",
    "X.fit_transform(train.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = X.get_feature_names()\n",
    "df = pd.DataFrame(columns=[\"sentimiento\"] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(train.keys()):\n",
    "    valor = X.transform([train[val]]).toarray()\n",
    "    df.loc[len(df)] = [val[0:3]] + list(valor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.get_feature_names()\n",
    "df_test = pd.DataFrame(columns=[\"sentimiento\"] + features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(test.keys()):\n",
    "    valor = X.transform([test[val]]).toarray()\n",
    "    df_test.loc[len(df_test)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creem el model inicial, farem servir random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train: 1.0 \n",
      " Accuracy en test: 0.775 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train.sample(frac=1, replace= True, random_state=22)\n",
    "df_test.sample(frac=1, replace= True, random_state=22)\n",
    "\n",
    "y_train = df_train[\"sentimiento\"]\n",
    "x_train = df_train.drop(columns=[\"sentimiento\"])\n",
    "\n",
    "y_test = df_test[\"sentimiento\"]\n",
    "x_test = df_test.drop(columns=[\"sentimiento\"])\n",
    "# Crear un modelo de Random Forest con 100 árboles\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=22)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Predecir la clase de los datos de prueba\n",
    "y_pred_train = rf.predict(x_train)\n",
    "y_pred_test = rf.predict(x_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, y_pred_train)} \\n Accuracy en test: {accuracy_score(y_test, y_pred_test)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature  importance\n",
      "16           bad    0.051898\n",
      "84          life    0.017009\n",
      "118  performance    0.014997\n",
      "46          film    0.014202\n",
      "57         great    0.014100\n",
      "..           ...         ...\n",
      "99          meet    0.002978\n",
      "151         sure    0.002642\n",
      "124     probably    0.002613\n",
      "69       instead    0.002564\n",
      "33        direct    0.002552\n",
      "\n",
      "[180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las importancias de las características\n",
    "df_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "\n",
    "# Ordenar el DataFrame por importancia descendente\n",
    "df_importances = df_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "print(df_importances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo\n",
    "\n",
    "Como se puede observar, el modelo toma mayor consideración a la hora de clasificar un texto cuando aparece la palabra **bad**, tambien cabe destacar que existen palabras que se fija el modelo que no tienen sentido en cuanto a significado, como preposiciones o adverbios. Es por ello, que se modificará el train para que solo se fije en nombres, adjetivos y verbos. Además, así podremos reducir la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = {}\n",
    "\n",
    "for i in train.keys():\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(train[i]))\n",
    "    frase = \"\"\n",
    "    for val in tags:\n",
    "        if val[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','NN', 'NNS', 'JJ', 'JJR', 'JJS']:\n",
    "            frase += val[0] + \" \"\n",
    "    new_train[i] = frase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vegada que hem obtingut verbs, noms y adjectius, n'hem a entrenar el nostre count vectorizer en el train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\pelot\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = CountVectorizer(strip_accents='ascii',lowercase=True,tokenizer=tokenitzador,stop_words=stop_words, min_df=0.2)\n",
    "X.fit_transform(new_train.values())\n",
    "\n",
    "features = X.get_feature_names()\n",
    "df_train = pd.DataFrame(columns=[\"sentimiento\"] + features)\n",
    "\n",
    "for i, val in enumerate(new_train.keys()):\n",
    "    valor = X.transform([new_train[val]]).toarray()\n",
    "    df_train.loc[len(df_train)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.get_feature_names()\n",
    "df_test = pd.DataFrame(columns=[\"sentimiento\"] + features)\n",
    "\n",
    "for i, val in enumerate(test.keys()):\n",
    "    valor = X.transform([test[val]]).toarray()\n",
    "    df_test.loc[len(df_test)] = [val[0:3]] + list(valor[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creem el model ambs els mateixos hiperparámetres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en train: 1.0 \n",
      "Accuracy en test: 0.79 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train.sample(frac=1, replace= True, random_state=22)\n",
    "df_test.sample(frac=1, replace= True, random_state=22)\n",
    "\n",
    "y_train = df_train[\"sentimiento\"]\n",
    "x_train = df_train.drop(columns=[\"sentimiento\"])\n",
    "\n",
    "y_test = df_test[\"sentimiento\"]\n",
    "x_test = df_test.drop(columns=[\"sentimiento\"])\n",
    "# Crear un modelo de Random Forest con 100 árboles\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=22)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Predecir la clase de los datos de prueba\n",
    "y_pred_train = rf.predict(x_train)\n",
    "y_pred_test = rf.predict(x_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, y_pred_train)} \\nAccuracy en test: {accuracy_score(y_test, y_pred_test)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.81      0.79       100\n",
      "         pos       0.80      0.77      0.79       100\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x202a0654c08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(classification_report(y_pred= y_pred_test, y_true= y_test))\n",
    "print(\"===========================================================\")\n",
    "a = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test), display_labels=[\"neg\", \"pos\"])\n",
    "a.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirem la importància de les labels en el nou model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        feature  importance\n",
      "6           bad    0.056992\n",
      "65         life    0.019883\n",
      "30         film    0.019224\n",
      "41        great    0.017703\n",
      "83        movie    0.017414\n",
      "..          ...         ...\n",
      "82         move    0.003895\n",
      "9       believe    0.003838\n",
      "79         mind    0.003819\n",
      "52  interesting    0.003781\n",
      "69         long    0.003691\n",
      "\n",
      "[139 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las importancias de las características\n",
    "df_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "\n",
    "# Ordenar el DataFrame por importancia descendente\n",
    "df_importances = df_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "print(df_importances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot observar, Hem reduit, en unes 60 paraules la quantitat de paraules a tenir en compte a l'hora de classificar els diferents textos. A més a més, hem aconseguit la mateixa accuracy que en l'anterior model tenint menys labels, per tant, s'ha reduit la dimensionalitat adequadament.\n",
    "\n",
    "Com es pot observar, al reduir les variables, augmenten les importàncies de les labels en el model, on la més important segueix sent **bad**.\n",
    "\n",
    "Si s'observa el report de classificcació, es pot observar com per la classe negatiu tenim més precissió que la positiva, això pot ser degut a la paraula \"bad\", que ajuda a la precisió de la negativa però pot ser existeixen exemples que no la tenen i per tant, no arribar a reconèixer bé la classe (el nivell de recall és més inferior)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model no supervisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-03-29']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecha_str = \"2023-03-29\"\n",
    "patron = r\"\\d{4}-\\d{2}-\\d{2}\"\n",
    "\n",
    "fecha_match = re.findall(patron, fecha_str)\n",
    "fecha_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació es fará diversos dataframes, on guardarem els valors positius dels sinsets i altre on hi hagi els valors negatius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\pelot\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize(p):\n",
    "  d = {'NN': 'n', 'NNS': 'n', \n",
    "       'JJ': 'a', 'JJR': 'a', 'JJS': 'a', \n",
    "       'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v', \n",
    "       'RB': 'r', 'RBR': 'r', 'RBS': 'r'}\n",
    "  if p[1] in d:\n",
    "    return [wnl.lemmatize(p[0], pos=d[p[1]]), d[p[1]]]\n",
    "  return [p[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_no_supervisat(dades:dict):\n",
    "    dd = pd.DataFrame(columns=[\"Exemple\", \"quantitat_pos\", \"quantitat_neg\", \"prediccio\", \"true_label\"])\n",
    "    for tag in dades.keys():\n",
    "        exemple = nltk.word_tokenize(dades[tag])\n",
    "        exemple_tagged = nltk.pos_tag(exemple)\n",
    "        quant_pos = 0\n",
    "        quant_neg = 0\n",
    "        for x in range(len(exemple)):\n",
    "            lema = lemmatize(exemple_tagged[x])\n",
    "            if len(lema) == 1:\n",
    "                quant_neg += 0\n",
    "                quant_pos += 0\n",
    "            else:\n",
    "                synset = nltk.wsd.lesk(exemple, exemple[x], lema[1])\n",
    "                if synset is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    senti = swn.senti_synset(synset.name())\n",
    "                    quant_neg += senti.neg_score()\n",
    "                    quant_pos += senti.pos_score()\n",
    "\n",
    "        resultat = \"neg\" if quant_neg > quant_pos else \"pos\"\n",
    "        dd.loc[len(dd)] = [tag] + [quant_pos] + [quant_neg] + [resultat] + [tag[0:3]]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_train_pred = model_no_supervisat(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.66      0.32      0.43       900\n",
      "         pos       0.55      0.83      0.66       900\n",
      "\n",
      "    accuracy                           0.58      1800\n",
      "   macro avg       0.60      0.58      0.55      1800\n",
      "weighted avg       0.60      0.58      0.55      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dd_train_pred[\"true_label\"], dd_train_pred[\"prediccio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_final = model_no_supervisat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exemple</th>\n",
       "      <th>quantitat_pos</th>\n",
       "      <th>quantitat_neg</th>\n",
       "      <th>prediccio</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg/cv900_10800.txt</td>\n",
       "      <td>16.625</td>\n",
       "      <td>15.250</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg/cv901_11934.txt</td>\n",
       "      <td>5.750</td>\n",
       "      <td>6.875</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg/cv902_13217.txt</td>\n",
       "      <td>25.375</td>\n",
       "      <td>24.250</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg/cv903_18981.txt</td>\n",
       "      <td>10.875</td>\n",
       "      <td>7.500</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg/cv904_25663.txt</td>\n",
       "      <td>6.250</td>\n",
       "      <td>7.875</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>pos/cv995_21821.txt</td>\n",
       "      <td>38.875</td>\n",
       "      <td>16.125</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>pos/cv996_11592.txt</td>\n",
       "      <td>11.125</td>\n",
       "      <td>10.500</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>pos/cv997_5046.txt</td>\n",
       "      <td>30.250</td>\n",
       "      <td>32.625</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pos/cv998_14111.txt</td>\n",
       "      <td>22.500</td>\n",
       "      <td>15.500</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>pos/cv999_13106.txt</td>\n",
       "      <td>33.500</td>\n",
       "      <td>24.125</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Exemple  quantitat_pos  quantitat_neg prediccio true_label\n",
       "0    neg/cv900_10800.txt         16.625         15.250       pos        neg\n",
       "1    neg/cv901_11934.txt          5.750          6.875       neg        neg\n",
       "2    neg/cv902_13217.txt         25.375         24.250       pos        neg\n",
       "3    neg/cv903_18981.txt         10.875          7.500       pos        neg\n",
       "4    neg/cv904_25663.txt          6.250          7.875       neg        neg\n",
       "..                   ...            ...            ...       ...        ...\n",
       "195  pos/cv995_21821.txt         38.875         16.125       pos        pos\n",
       "196  pos/cv996_11592.txt         11.125         10.500       pos        pos\n",
       "197   pos/cv997_5046.txt         30.250         32.625       neg        pos\n",
       "198  pos/cv998_14111.txt         22.500         15.500       pos        pos\n",
       "199  pos/cv999_13106.txt         33.500         24.125       pos        pos\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.62      0.28      0.39       100\n",
      "         pos       0.54      0.83      0.65       100\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.58      0.55      0.52       200\n",
      "weighted avg       0.58      0.56      0.52       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dd_final[\"true_label\"], dd_final[\"prediccio\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment:\n",
    "Y si li donem més pes als adjectius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = {\"n\":1, \"a\":3, \"v\":1, \"r\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_no_supervisat(dades:dict, pesos):\n",
    "    dd = pd.DataFrame(columns=[\"Exemple\", \"quantitat_pos\", \"quantitat_neg\", \"prediccio\", \"true_label\"])\n",
    "    for tag in dades.keys():\n",
    "        exemple = nltk.word_tokenize(dades[tag])\n",
    "        exemple_tagged = nltk.pos_tag(exemple)\n",
    "        quant_pos = 0\n",
    "        quant_neg = 0\n",
    "        for x in range(len(exemple)):\n",
    "            lema = lemmatize(exemple_tagged[x])\n",
    "            if len(lema) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                synset = nltk.wsd.lesk(exemple, exemple[x], lema[1])\n",
    "                if synset is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    senti = swn.senti_synset(synset.name())\n",
    "                    quant_neg += senti.neg_score()*pesos[lema[1]]\n",
    "                    quant_pos += senti.pos_score()*pesos[lema[1]]\n",
    "\n",
    "        resultat = \"neg\" if quant_neg > quant_pos else \"pos\"\n",
    "        dd.loc[len(dd)] = [tag] + [quant_pos] + [quant_neg] + [resultat] + [tag[0:3]]\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_test_pred = model_no_supervisat(test, pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.63      0.42      0.50       100\n",
      "         pos       0.56      0.75      0.64       100\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.60      0.58      0.57       200\n",
      "weighted avg       0.60      0.58      0.57       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dd_test_pred[\"true_label\"], dd_test_pred[\"prediccio\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si fem que els adverbis no comptin i reduim el pes tant per noms com per verbs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.64      0.49      0.55       100\n",
      "         pos       0.59      0.72      0.65       100\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.61      0.60      0.60       200\n",
      "weighted avg       0.61      0.60      0.60       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pesos = {\"n\":0.2, \"a\":3, \"v\":0.2, \"r\":0}\n",
    "dd_test_pred = model_no_supervisat(test, pesos)\n",
    "print(classification_report(dd_test_pred[\"true_label\"], dd_test_pred[\"prediccio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.65      0.51      0.57       900\n",
      "         pos       0.59      0.72      0.65       900\n",
      "\n",
      "    accuracy                           0.61      1800\n",
      "   macro avg       0.62      0.61      0.61      1800\n",
      "weighted avg       0.62      0.61      0.61      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pesos = {\"n\":0.2, \"a\":3, \"v\":0.3, \"r\":0.2}\n",
    "dd_test_pred = model_no_supervisat(train, pesos)\n",
    "print(classification_report(dd_test_pred[\"true_label\"], dd_test_pred[\"prediccio\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
